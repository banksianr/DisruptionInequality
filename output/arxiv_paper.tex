\documentclass[12pt, letterpaper]{article}

% ── Packages ──────────────────────────────────────────────────────────────────
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\usepackage{caption}
\usepackage{float}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

\onehalfspacing

% ── Title ─────────────────────────────────────────────────────────────────────

\title{\textbf{How Concentrated Is Disruptive Research?\\A Corrected Analysis of 10,000 STEM Authors}}

\author{
    Ian Banks\textsuperscript{1} \and Claude\textsuperscript{2}\\[6pt]
    \textsuperscript{1}\textit{Foundation for American Innovation}\\
    \textsuperscript{2}\textit{Anthropic}
}

\date{\today}

% ══════════════════════════════════════════════════════════════════════════════

\begin{document}

\maketitle

% ── Abstract ──────────────────────────────────────────────────────────────────

\begin{abstract}
We investigate whether disruptive scientific research is concentrated among a small fraction of scientists, using bibliometric data from OpenAlex covering 10,000 randomly sampled STEM authors. Using the A/B disruption index, we initially found extreme concentration (Gini = 0.90), but a methodological audit revealed two problems: (1) papers with few references produce artificially extreme disruption scores, and (2) computing the Gini coefficient on a zero-inflated count variable (number of ``top-5\%'' papers per author) yields a value that mechanically approximates the fraction of authors with zero disruptive papers, rather than measuring meaningful inequality. After correcting for reference-count bias and switching to continuous disruption scores, we find \emph{moderate} inequality (Gini = 0.36, 95\% CI: [0.35, 0.38]) that is \emph{less} concentrated than citation counts (Gini = 0.57). The top 5\% of scientists account for 12.3\% of total disruption score mass---notable but far from the 50.3\% initially reported. These corrected findings are stable across six five-year windows (1980--2009) and consistent across STEM subfields. We present this as a case study in how common bibliometric analysis choices---thresholding continuous scores into binary indicators, neglecting reference-count confounds, and applying inequality measures to zero-inflated distributions---can produce misleading conclusions.
\end{abstract}

\medskip
\noindent\textbf{Keywords:} disruption index, scientific productivity, Gini coefficient, metascience, bibliometrics, methodological correction

\newpage

% ── 1. Introduction ──────────────────────────────────────────────────────────

\section{Introduction}

A small number of scientific papers reshape entire fields, while the vast majority consolidate existing knowledge. The disruption index \citep{funk2017, wu2019} attempts to measure this distinction: it classifies each paper's subsequent citations as either ``displacing'' prior work (disruptive) or ``building on'' prior work alongside the focal paper (consolidating). Using this measure, \citet{park2023} documented a broad decline in disruptive science over six decades.

A natural follow-up question is whether disruptive research is concentrated among a small fraction of scientists---a ``disruptor elite.'' We set out to test this hypothesis using 10,000 randomly sampled STEM authors from OpenAlex. Our initial analysis appeared to show extreme concentration: a Gini coefficient of 0.90 for disruptive output, far exceeding the Gini for citations (0.66). However, a replication audit uncovered two methodological problems that dramatically inflated our concentration estimates. This paper reports both the flawed and corrected analyses, as we believe the methodological lessons are as important as the substantive findings.

\subsection{What We Set Out to Test}

Our hypothesis was: \emph{only a very small percentage of scientists produce very disruptive research.} We operationalized this using the A/B disruption index and asked three questions:

\begin{enumerate}
    \item How unequally is disruptive research output distributed among scientists?
    \item What distinguishes scientists who produce disruptive work from those who do not?
    \item Is this pattern stable across time periods and scientific fields?
\end{enumerate}

% ── 2. Data and Methods ──────────────────────────────────────────────────────

\section{Data and Methods}

This section explains each step of our analysis in plain terms. Where statistical concepts are used, we define them.

\subsection{Step 1: Sampling Scientists}

We drew a random sample of 10,000 STEM authors from OpenAlex, a free bibliometric database indexing over 200 million scholarly works \citep{priem2022}. To focus on active researchers, we required each author to have at least 5 publications and 10 citations. We identified STEM authors by matching their listed research topics against 43 keywords spanning physics, chemistry, biology, mathematics, computer science, engineering, and medicine.

For each author, we retrieved all articles and reviews published between 1980 and 2010, yielding 109,527 works. The 2010 cutoff ensures that every paper has at least a 10-year window for accumulating citations---important because disruption scores depend on citation patterns that take years to develop.

\subsection{Step 2: Computing Disruption Scores}

The disruption index measures whether a paper \emph{displaces} or \emph{consolidates} prior work. The intuition is:

\begin{itemize}
    \item A \textbf{disruptive} paper causes future researchers to cite it \emph{instead of} the papers it built on. (Future work treats it as the new starting point.)
    \item A \textbf{consolidating} paper causes future researchers to cite it \emph{alongside} the papers it built on. (Future work treats it as one contribution among many in an established line of research.)
\end{itemize}

Formally, for a focal paper $p$ that cites a set of references $R$, we look at every paper that cites $p$ within 10 years and classify each as:
\begin{itemize}
    \item \textbf{Type A} (disruptive signal): cites $p$ but does \emph{not} cite any paper in $R$
    \item \textbf{Type B} (consolidating signal): cites both $p$ and at least one paper in $R$
\end{itemize}

The disruption score is:
\begin{equation}
    D_{AB} = \frac{A - B}{A + B}
\end{equation}

This ranges from $-1$ (purely consolidating: every citing paper also cites the references) to $+1$ (purely disruptive: no citing paper also cites the references). A score of 0 means an equal mix. We required at least 5 citing papers for a valid score.

From the 109,527 works, we randomly selected 5,000 papers with at least one reference for disruption scoring, obtaining valid scores for 3,421 papers across 1,594 unique authors.

\subsection{Step 3: The Reference-Count Problem}

\textbf{This is a critical methodological point.} A paper's disruption score is mechanically influenced by how many references it cites:

\begin{itemize}
    \item A paper with \textbf{3 references}: it is easy for a citing paper to avoid all 3 references by chance, producing a Type~A (``disruptive'') classification even if the work is not truly paradigm-shifting.
    \item A paper with \textbf{30 references}: it is much harder for a citing paper to avoid \emph{all} 30 references, so consolidating classifications are more likely.
\end{itemize}

In our data, this bias is dramatic. Among papers with $\leq 5$ references, 29\% received the maximum disruption score of $D = +1.0$. Among papers with $\geq 20$ references, only 0.3\% did (Table~\ref{tab:refbias}). The average disruption score for low-reference papers ($+0.36$) is far higher than for well-referenced papers ($-0.50$).

\begin{table}[H]
\centering
\caption{Reference Count Bias in Disruption Scores}
\label{tab:refbias}
\begin{tabular}{@{}lcccc@{}}
\toprule
Reference Count & $N$ Papers & Mean CD5 & \% at $D = +1$ & \% at $D = -1$ \\
\midrule
$\leq 5$   & 145   & $+0.36$  & 29.0\% & 2.1\% \\
6--10      & 308   & $-0.11$  & 3.2\%  & 5.5\% \\
11--20     & 813   & $-0.33$  & 1.0\%  & 7.1\% \\
$> 20$     & 2,258 & $-0.50$  & 0.3\%  & 7.7\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Correction applied:} For our main analysis, we exclude papers with fewer than 10 references. This reduces the sample from 3,421 to 3,045 papers across 1,463 authors, but dramatically reduces the artificial inflation of disruption scores (papers at $D = +1$ drop from 2.1\% to 0.6\%).

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig3_ref_count_bias.png}
\caption{\textit{Left:} Scatter plot showing that papers with fewer references tend to receive higher (more ``disruptive'') scores. \textit{Right:} The percentage of papers with positive disruption drops sharply as reference count increases. This demonstrates that low reference counts mechanically inflate disruption scores.}
\label{fig:refbias}
\end{figure}

\subsection{Step 4: Measuring Concentration}

To measure how unequally disruption is distributed across scientists, we use two tools:

\paragraph{The Gini coefficient} is a number between 0 and 1 that measures inequality.
\begin{itemize}
    \item \textbf{Gini = 0} means perfect equality: every scientist has the same disruption score.
    \item \textbf{Gini = 1} means perfect inequality: one scientist has everything, everyone else has nothing.
    \item For context, U.S.\ household income has a Gini of about 0.49.
\end{itemize}

\paragraph{The Lorenz curve} is a graph that visualizes inequality. Scientists are lined up from lowest to highest disruption score. The curve shows: ``if you include the bottom $X$\% of scientists, what fraction of total disruption do they account for?'' A 45-degree line means perfect equality; the further the curve bows below the line, the more unequal the distribution.

\paragraph{Concentration ratios} answer: ``What share of total disruption comes from the top 1\%, 5\%, 10\%, and 25\% of scientists?''

\subsection{Step 5: The Zero-Inflation Problem}

\textbf{This is the second critical methodological point.} Our initial analysis computed the Gini coefficient on the \emph{count of top-5\% disruptive papers per author}. This variable is mostly zeros: 89.9\% of authors produced zero top-5\% papers.

The problem: when you compute a Gini coefficient on data that is 90\% zeros, the result is mechanically $\approx 0.90$---regardless of any real concentration pattern. The Gini is simply reflecting the base rate of a rare event, not measuring meaningful inequality.

\textbf{Analogy:} Suppose you ask ``how concentrated is Olympic gold medal winning among all recreational runners?'' If you compute a Gini coefficient on the number of gold medals per person (99.999\% of whom have zero), you would get a Gini $\approx 1.0$ and conclude ``extreme concentration!'' But this is trivially true and uninformative---of course most people don't win Olympic gold.

\textbf{Correction applied:} Instead of the binary/count measure, we compute the Gini on each author's \emph{continuous peak disruption score} (their highest-scoring paper). This variable has no zeros (every author with a scored paper has some max score) and captures the full range of disruption rather than collapsing it into ``disruptive or not.''

\subsection{Step 6: Demographic Comparison}

We compare scientists who produced at least one top-5\% disruptive paper (``disruptors'') against those who did not (``non-disruptors'') on simple descriptive statistics: team size, career length, h-index, and citations per paper. No complex models are needed for the descriptive findings; the contrasts are straightforward.

\subsection{Step 7: Consistency Checks}

We check whether the results hold up across:
\begin{itemize}
    \item \textbf{Time periods}: six five-year windows from 1980--84 through 2005--09.
    \item \textbf{Scientific fields}: 15 STEM subfields with $\geq 20$ authors each.
\end{itemize}

\subsection{Step 8: Validation}

We compare our disruption score distribution against the \citet{park2023} Zenodo dataset of 22.5 million CD5 scores from Web of Science as a population-level benchmark. Because that dataset lacks per-paper identifiers, we compare distributional shapes rather than matching individual papers.

% ── 3. Results ────────────────────────────────────────────────────────────────

\section{Results}

\subsection{What the Flawed Analysis Showed}

Before describing the corrected results, we report the initial (flawed) findings to illustrate the magnitude of the methodological distortion.

\begin{table}[H]
\centering
\caption{Comparison of Initial (Flawed) vs.\ Corrected Analysis}
\label{tab:comparison}
\begin{tabular}{@{}lcc@{}}
\toprule
Metric & Initial (Flawed) & Corrected \\
\midrule
Papers analyzed         & 3,421            & 3,045 \\
Authors analyzed        & 1,594            & 1,463 \\
Gini coefficient        & 0.900            & 0.363 \\
Gini interpretation     & ``Extreme''      & ``Moderate'' \\
Top 5\% share           & 50.3\%           & 12.3\% \\
Top 10\% share          & 92.1\%           & 22.5\% \\
vs.\ citation Gini     & Higher (0.66)    & Lower (0.57) \\
Disruption measure      & Count of top-5\% papers & Continuous peak score \\
Reference filter        & None             & $\geq 10$ references \\
\bottomrule
\end{tabular}
\end{table}

The initial analysis overstated concentration by a factor of roughly 2.5$\times$ (Gini) and 4$\times$ (top-5\% share). The direction of the comparison with citations \emph{reversed}: disruption went from appearing more concentrated than citations to less concentrated.

\subsection{Corrected Score Distribution}

After filtering to papers with $\geq 10$ references, the distribution of disruption scores shifts substantially. The fraction of papers at $D = +1.0$ drops from 2.1\% to 0.6\%, and the fraction with positive disruption drops from 18.4\% to 13.9\% (Figure~\ref{fig:scores}).

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig1_score_distribution.png}
\caption{Distribution of disruption scores before (\textit{left}) and after (\textit{right}) applying the reference-count filter ($\geq 10$ references). The filter removes most of the artificial spike at $D = +1.0$.}
\label{fig:scores}
\end{figure}

Most papers receive negative disruption scores, meaning they consolidate rather than displace prior work. This is consistent with the broader metascience finding that most research is ``normal science'' in Kuhn's sense \citep{kuhn1962}.

\subsection{Corrected Concentration of Disruption}

Using continuous peak disruption scores, the Gini coefficient is \textbf{0.363} (95\% CI: [0.351, 0.375]). This indicates moderate inequality---some scientists achieve notably higher peak disruption than others, but the distribution is far from the ``extreme concentration'' suggested by the flawed analysis.

For comparison, the Gini for mean citations per paper across the same authors is \textbf{0.565} (95\% CI: [0.523, 0.610]). Disruption is \emph{less} unequally distributed than citations.

\begin{table}[H]
\centering
\caption{Concentration Ratios (Corrected, Continuous Scores)}
\label{tab:concentration}
\begin{tabular}{@{}lc@{}}
\toprule
Author Percentile & Share of Total Disruption Score Mass \\
\midrule
Top 1\%  & 2.6\% \\
Top 5\%  & 12.3\% \\
Top 10\% & 22.5\% \\
Top 25\% & 47.4\% \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig2_author_distribution.png}
\caption{\textit{Left:} Distribution of peak disruption scores across 1,463 authors. The median is $-0.33$, meaning the typical scientist's best paper is mildly consolidating. \textit{Right:} Lorenz curves for disruption (Gini = 0.36) and citations (Gini = 0.57). Disruption is more equally distributed than citations.}
\label{fig:lorenz}
\end{figure}

In plain terms: the top 5\% of scientists account for about 12\% of total disruption---some concentration, but comparable to many real-world distributions and far from the ``winner-take-all'' pattern that a Gini of 0.90 would imply.

\subsection{Disruptor Profile}

Comparing the 148 scientists who produced at least one top-5\% disruptive paper against the 1,315 who did not:

\begin{table}[H]
\centering
\caption{Median Values: Disruptors vs.\ Non-Disruptors}
\label{tab:profile}
\begin{tabular}{@{}lcc@{}}
\toprule
Variable & Disruptors ($n = 148$) & Non-Disruptors ($n = 1{,}315$) \\
\midrule
Team size (avg)          & 4.5   & 5.0 \\
Scored papers            & 2     & 1 \\
Career length (years)    & 19    & 13 \\
h-index                  & 23    & 17 \\
Citations per paper      & 35.7  & 41.0 \\
References per paper     & 25.5  & 30.0 \\
\bottomrule
\end{tabular}
\end{table}

The most notable difference is career length: disruptors have a median career span of 19 years versus 13 for non-disruptors. This likely reflects a simple statistical regularity---scientists who publish over more years have more chances to produce a high-scoring paper---rather than any deep insight about the nature of disruption. Disruptors also work in slightly smaller teams and, perhaps counterintuitively, receive somewhat \emph{fewer} citations per paper on average.

\subsection{Consistency Across Fields}

The moderate inequality pattern is remarkably consistent across STEM subfields (Table~\ref{tab:fields}). The continuous Gini ranges from 0.30 (Chemistry, Immunology) to 0.43 (Physics and Astronomy), a narrow band given the diversity of these fields.

\begin{table}[H]
\centering
\caption{Disruption Inequality by STEM Subfield (Continuous Gini)}
\label{tab:fields}
\begin{tabular}{@{}lccc@{}}
\toprule
Field & Gini & $N$ Authors & \% Disruptors \\
\midrule
Physics \& Astronomy        & 0.433 & 105 & 3.8\% \\
Neuroscience                & 0.402 & 42  & 4.8\% \\
Ag.\ \& Biological Sciences & 0.363 & 82  & 12.2\% \\
Biochem., Genetics \& Mol.\ Bio. & 0.362 & 232 & 9.1\% \\
Medicine                    & 0.360 & 391 & 10.7\% \\
Computer Science            & 0.351 & 59  & 8.5\% \\
Engineering                 & 0.351 & 142 & 14.1\% \\
Materials Science           & 0.345 & 68  & 8.8\% \\
Health Professions          & 0.341 & 25  & 28.0\% \\
Environmental Science       & 0.322 & 61  & 9.8\% \\
Chemistry                   & 0.302 & 66  & 15.2\% \\
\bottomrule
\multicolumn{4}{@{}l}{\footnotesize 11 fields with $\geq 20$ authors and $\geq 1$ disruptor shown (1,273 of 1,463 authors).}\\
\multicolumn{4}{@{}l}{\footnotesize Remaining authors in smaller fields or fields with zero disruptors.}\\
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.85\textwidth]{fig4_field_comparison.png}
\caption{Gini coefficients for peak disruption across STEM subfields. All fall in a narrow range (0.30--0.43), with the overall average of 0.36 shown as a dashed line.}
\label{fig:fields}
\end{figure}

\subsection{Stability Over Time}

The concentration of disruption is stable across three decades (Table~\ref{tab:temporal}). The continuous Gini fluctuates in a narrow band (0.38--0.41) with no discernible trend.

\begin{table}[H]
\centering
\caption{Disruption Inequality by Five-Year Window (Continuous Gini)}
\label{tab:temporal}
\begin{tabular}{@{}lcccc@{}}
\toprule
Window & Gini & \% Disruptors & $N$ Authors & $N$ Papers \\
\midrule
1980--84 & 0.413 & 6.7\%  & 90  & 111 \\
1985--89 & 0.388 & 7.2\%  & 139 & 188 \\
1990--94 & 0.404 & 7.3\%  & 178 & 251 \\
1995--99 & 0.376 & 6.2\%  & 289 & 377 \\
2000--04 & 0.380 & 6.5\%  & 478 & 650 \\
2005--09 & 0.393 & 7.5\%  & 765 & 1{,}158 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{fig5_temporal.png}
\caption{Temporal trends in disruption inequality. \textit{Left:} Gini coefficient (continuous) is stable around 0.39. \textit{Right:} The fraction of scientists producing top-5\% disruptive papers is stable at 6--7\%.}
\label{fig:temporal}
\end{figure}

% ── 4. Discussion ─────────────────────────────────────────────────────────────

\section{Discussion}

\subsection{What We Found}

Disruptive research is moderately unequally distributed among scientists, with a Gini of 0.36 on continuous peak disruption scores. This is \emph{less} unequal than citation counts (Gini = 0.57), stable across time, and consistent across STEM fields. About 10\% of scientists produce at least one top-5\% disruptive paper, and the top 5\% of scientists account for about 12\% of total disruption---meaningful but not extreme concentration.

\subsection{What We Got Wrong Initially, and Why It Matters}

Our initial analysis reported a Gini of 0.90 and claimed ``extreme concentration.'' This was wrong for two compounding reasons:

\paragraph{Lesson 1: The Gini coefficient on zero-inflated counts is misleading.} When you define ``disruptive'' as the top 5\% and then compute a Gini on the count of disruptive papers per author, $\sim$90\% of authors have zero by construction. The Gini then mechanically equals $\sim$0.90 regardless of any real concentration pattern. This is a general hazard in bibliometrics: anytime a Gini is computed on a count variable where most observations are zero (e.g., number of papers in \textit{Nature}, number of patents, number of grants), the result primarily reflects the rarity of the event rather than inequality in the underlying ability.

\paragraph{Lesson 2: Low-reference papers produce artifactually extreme disruption scores.} Papers citing fewer than 10 references are mechanically more likely to receive disruption scores near $+1.0$, because it is easy for citing papers to avoid all references by chance. This inflates the right tail of the disruption distribution and misclassifies many ordinary papers as ``disruptive.'' The same bias likely affects population-level analyses that do not control for reference count.

Together, these two errors created a cascade: inflated disruption scores pushed more papers above the top-5\% threshold, which inflated the count of ``disruptive papers'' for some authors, which inflated the Gini on those counts. Each step amplified the distortion.

\subsection{Relation to Prior Work}

Our corrected findings are consistent with \citet{park2023}'s observation that most papers are consolidating rather than disruptive. The moderate inequality we observe (Gini = 0.36) is lower than the inequality of citations (Gini = 0.57), suggesting that the capacity to produce \emph{some} disruptive work is more broadly distributed among scientists than the capacity to accumulate citations. This may reflect the fact that disruption and prestige are partially orthogonal: disruptive papers may be controversial, slow to accumulate citations, or published in unexpected venues \citep{wu2019}.

\subsection{Limitations}

\begin{itemize}
    \item \textbf{Sample size}: Our disruption scores cover 3,045 papers across 1,463 authors---far smaller than population-level studies. Results may not generalize to all of science.
    \item \textbf{Disruption metric}: The A/B variant omits Type C citers and uses a 10-year window rather than the standard 5 years, producing more extreme scores than the standard CD5 index.
    \item \textbf{Career length}: We measure career length using the author's earliest publication year recorded in OpenAlex, which may be incomplete for authors with sparse early records.
    \item \textbf{STEM only}: We do not address the social sciences or humanities.
    \item \textbf{Observational}: All comparisons are descriptive. The association between career length and disruption likely reflects survivorship bias rather than a causal effect.
    \item \textbf{Publication window}: Works were fetched for 1980--2010 only. The 2010 cutoff was chosen to guarantee at least a 10-year forward citation window (through 2020+) for every paper. Extending to 2014 would add four years of data but reduce the forward window to 6 years for the newest papers; extending further would increasingly compromise the disruption computation. A future replication with a 2014 endpoint and 5-year forward window (matching the standard CD5 definition) would be a natural extension.
\end{itemize}

% ── 5. Conclusion ─────────────────────────────────────────────────────────────

\section{Conclusion}

Disruptive research output is moderately unequally distributed among STEM scientists---less so than citations, stable over time, and consistent across fields. The initially reported ``extreme concentration'' (Gini = 0.90) was an artifact of two methodological choices: applying an inequality measure to a zero-inflated count variable, and failing to control for the mechanical relationship between reference counts and disruption scores. We present these corrections not as a criticism of the disruption index itself, but as a cautionary example of how standard bibliometric analysis steps can compound to produce misleading results. Researchers using the disruption index should (1) filter for minimum reference counts and (2) avoid computing Gini coefficients on thresholded count variables.

% ── Data and Code Availability ────────────────────────────────────────────────

\section*{Data and Code Availability}

All analysis code and cached data are available at \url{https://github.com/banksianr/DisruptionInequality}. The pipeline is implemented in Python and uses the OpenAlex API \citep{priem2022} for bibliometric data and the \citet{park2023} Zenodo dataset (Record 7258379) for population benchmarking.

% ── References ────────────────────────────────────────────────────────────────

\bibliographystyle{plainnat}

\begin{thebibliography}{99}

\bibitem[Funk and Owen-Smith(2017)]{funk2017}
Funk, R.~J., \& Owen-Smith, J. (2017).
\newblock A dynamic network measure of technological change.
\newblock \textit{Management Science}, 63(3), 791--817.

\bibitem[Kuhn(1962)]{kuhn1962}
Kuhn, T.~S. (1962).
\newblock \textit{The Structure of Scientific Revolutions}.
\newblock University of Chicago Press.

\bibitem[Park et~al.(2023)]{park2023}
Park, M., Leahey, E., \& Funk, R.~J. (2023).
\newblock Papers and patents are becoming less disruptive over time.
\newblock \textit{Nature}, 613, 138--144.

\bibitem[Priem et~al.(2022)]{priem2022}
Priem, J., Piwowar, H., \& Orber, R. (2022).
\newblock OpenAlex: A fully-open index of scholarly works, authors, venues, institutions, and concepts.
\newblock \textit{arXiv preprint} arXiv:2205.01833.

\bibitem[Wu et~al.(2019)]{wu2019}
Wu, L., Wang, D., \& Evans, J.~A. (2019).
\newblock Large teams develop and small teams disrupt science and technology.
\newblock \textit{Nature}, 566, 378--382.

\end{thebibliography}

\end{document}
